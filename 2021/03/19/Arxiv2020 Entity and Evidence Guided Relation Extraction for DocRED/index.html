<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
<meta name="viewport"
      content="width=device-width, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">

    <meta name="author" content="Chenhs">





<title>Arxiv2020 | Entity and Evidence Guided Relation Extraction for DocRED | Chenhs</title>



    <link rel="icon" href="/favicon.ico">




    <!-- stylesheets list from _config.yml -->
    
    <link rel="stylesheet" href="/css/style.css">
    



    <!-- scripts list from _config.yml -->
    
    <script src="/js/script.js"></script>
    
    <script src="/js/tocbot.min.js"></script>
    



    
    
        <!-- MathJax配置，可通过单美元符号书写行内公式等 -->
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
    "HTML-CSS": {
        preferredFont: "TeX",
        availableFonts: ["STIX","TeX"],
        linebreaks: { automatic:true },
        EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50)
    },
    tex2jax: {
        inlineMath: [ ["$", "$"], ["\\(","\\)"] ],
        processEscapes: true,
        ignoreClass: "tex2jax_ignore|dno",
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
        equationNumbers: { autoNumber: "AMS" },
        noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } },
        Macros: { href: "{}" }
    },
    messageStyle: "none"
    });
</script>
<!-- 给MathJax元素添加has-jax class -->
<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<!-- 通过连接CDN加载MathJax的js代码 -->
<script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


    


<meta name="generator" content="Hexo 5.4.0"></head>
<body>
    <div class="wrapper">
        <header>
    <nav class="navbar">
        <div class="container">
            <div class="navbar-header header-logo"><a href="/">思录</a></div>
            <div class="menu navbar-right">
                
                    <a class="menu-item" href="/archives">Posts</a>
                
                    <a class="menu-item" href="/category">Categories</a>
                
                    <a class="menu-item" href="/tag">Tags</a>
                
                    <a class="menu-item" href="/Hi">About</a>
                
                    <a class="menu-item" href="/Lists">Lists</a>
                
                <input id="switch_default" type="checkbox" class="switch_default">
                <label for="switch_default" class="toggleBtn"></label>
            </div>
        </div>
    </nav>

    
    <nav class="navbar-mobile" id="nav-mobile">
        <div class="container">
            <div class="navbar-header">
                <div>
                    <a href="/">思录</a><a id="mobile-toggle-theme">·&nbsp;Light</a>
                </div>
                <div class="menu-toggle" onclick="mobileBtn()">&#9776; Menu</div>
            </div>
            <div class="menu" id="mobile-menu">
                
                    <a class="menu-item" href="/archives">Posts</a>
                
                    <a class="menu-item" href="/category">Categories</a>
                
                    <a class="menu-item" href="/tag">Tags</a>
                
                    <a class="menu-item" href="/Hi">About</a>
                
                    <a class="menu-item" href="/Lists">Lists</a>
                
            </div>
        </div>
    </nav>

</header>
<script>
    var mobileBtn = function f() {
        var toggleMenu = document.getElementsByClassName("menu-toggle")[0];
        var mobileMenu = document.getElementById("mobile-menu");
        if(toggleMenu.classList.contains("active")){
           toggleMenu.classList.remove("active")
            mobileMenu.classList.remove("active")
        }else{
            toggleMenu.classList.add("active")
            mobileMenu.classList.add("active")
        }
    }
</script>
        <div class="main">
            <div class="container">
    
    
        <div class="post-toc">
    <div class="tocbot-list">
    </div>
    <div class="tocbot-list-menu">
        <a class="tocbot-toc-expand" onclick="expand_toc()">Expand all</a>
        <a onclick="go_top()">Back to top</a>
        <a onclick="go_bottom()">Go to bottom</a>
    </div>
</div>

<script>
    document.ready(
        function () {
            tocbot.init({
                tocSelector: '.tocbot-list',
                contentSelector: '.post-content',
                headingSelector: 'h1, h2, h3, h4, h5',
                collapseDepth: 1,
                orderedList: false,
                scrollSmooth: true,
            })
        }
    )

    function expand_toc() {
        var b = document.querySelector(".tocbot-toc-expand");
        tocbot.init({
            tocSelector: '.tocbot-list',
            contentSelector: '.post-content',
            headingSelector: 'h1, h2, h3, h4, h5',
            collapseDepth: 6,
            orderedList: false,
            scrollSmooth: true,
        });
        b.setAttribute("onclick", "collapse_toc()");
        b.innerHTML = "Collapse all"
    }

    function collapse_toc() {
        var b = document.querySelector(".tocbot-toc-expand");
        tocbot.init({
            tocSelector: '.tocbot-list',
            contentSelector: '.post-content',
            headingSelector: 'h1, h2, h3, h4, h5',
            collapseDepth: 1,
            orderedList: false,
            scrollSmooth: true,
        });
        b.setAttribute("onclick", "expand_toc()");
        b.innerHTML = "Expand all"
    }

    function go_top() {
        window.scrollTo(0, 0);
    }

    function go_bottom() {
        window.scrollTo(0, document.body.scrollHeight);
    }

</script>
    

    
    <article class="post-wrap">
        <header class="post-header">
            <h1 class="post-title">Arxiv2020 | Entity and Evidence Guided Relation Extraction for DocRED</h1>
            
                <div class="post-meta">
                    
                        Author: <a itemprop="author" rel="author" href="/">Chenhs</a>
                    

                    
                        <span class="post-time">
                        Date: <a href="#">三月 19, 2021&nbsp;&nbsp;17:09:22</a>
                        </span>
                    
                    
                        <span class="post-category">
                    Category:
                            
                                <a href="/categories/NLP/">NLP</a>
                            
                        </span>
                    
                </div>
            
        </header>

        <div class="post-content">
            <h2 id="Snapshot"><a href="#Snapshot" class="headerlink" title="Snapshot"></a>Snapshot</h2><ul>
<li><p>论文来源：arXiv-2020.08 #JD AI Research#</p>
</li>
<li><p>面向任务：DocRE</p>
</li>
<li><p>方法分类：BERT-based</p>
</li>
<li><p>论文动机：</p>
<p>众所周知，文档内实体对关系的判断主要是依据与当前实体最相关的support/evidence sentence。根据这一动机设计一种可以引导预训练模型集中focus文档中最相关的位置，而往常PLMs在处理文档时需要同时encode关于所有实体对相关的信息。因此，attention values over all token are more uniform。同时suporting/evidence sentences can be used as an auxiliary task for explainable RE.</p>
</li>
<li><p>指标分数：Ign F1:60.3 ; F1:62.5(RoBERTa-large)</p>
<blockquote>
<p>并未提及BERT-based的test结果 。</p>
</blockquote>
</li>
<li><p>快看速评：论文动机很简单，方法也比较优雅。但是对方法的合理性（比如在头部拼接实体是否真正可以起到引导预训练模型的fine-tuning有待考究），另外整个模型的计算复杂度肯定不低吧，自称SOTA，其实效果也勉勉强强，实验的分析比较单薄，这就是工业界论文的风格？</p>
</li>
<li><p>代码复现：待公开</p>
<div align="center">
        <img src="https://cdn.jsdelivr.net/gh/chenhaishun/test_pic@master/typora202103/11/150353-687394.png">  
    </a>
</div>

</li>
</ul>
<h2 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h2><div align="center">
        <img src="https://cdn.jsdelivr.net/gh/chenhaishun/test_pic@master/typora202103/11/152958-308751.png">  
    </a>
</div>

<h3 id="实体引导下的关系抽取"><a href="#实体引导下的关系抽取" class="headerlink" title="实体引导下的关系抽取"></a>实体引导下的关系抽取</h3><ol>
<li><p>要引导，怎么引导PLM关注当前实体呢？</p>
<p>A：生成Entity-guided Input Sequences，以此引导PLM towards the entities.(<u>合理性存疑</u>)</p>
<p>具体做法是在document前concatenate the first mention of a single entity.</p>
<p>表示为“[CLS]”+<em>H</em>+”[SEP]”+<em>D</em>+”[SEP]”, 当模型存在有$N_e$个实体，那么就会有$N_e$个新的输入。</p>
</li>
<li><p>文档首部合并实体之后经BERT得到Output后，下一步关系抽取怎么做？</p>
<p>head entity, tail entity与关系权重 $W_{i}$（learnable）相乘做线性变换：</p>
<script type="math/tex; mode=display">
\hat{y}_{i k}=\delta\left(\boldsymbol{h}^{T} \boldsymbol{W}_{i} \boldsymbol{t}_{k}+b_{i}\right)</script><p>此时的Loss定义为：</p>
<blockquote>
<p>到这一步，只能算是无脑BERT；</p>
</blockquote>
<script type="math/tex; mode=display">
\begin{aligned}
L_{R E} &=-\frac{1}{N_{r}} \frac{1}{N_{e}-1} \sum_{k=1}^{N_{e}-1} \sum_{i=1}^{N_{r}}\left(y_{i k} \log \left(\hat{y}_{i k}\right)\right.
\left.+\left(1-y_{i k}\right) \log \left(1-\hat{y}_{i k}\right)\right)
\end{aligned}</script></li>
</ol>
<h3 id="支撑句引导下的关系抽取"><a href="#支撑句引导下的关系抽取" class="headerlink" title="支撑句引导下的关系抽取"></a>支撑句引导下的关系抽取</h3><h4 id="支撑句预测："><a href="#支撑句预测：" class="headerlink" title="支撑句预测："></a>支撑句预测：</h4><p>预测一给定句子是否为一给定关系的支撑句。即sentence $j$ 是否为关系$r_i$的支撑句的分数：</p>
<blockquote>
<p>$k$ 表示尾实体的序号吗？如果不是，那尾部实体的信息从何体现呢？？如果是，哪里有尾实体的信息呢？奇奇怪怪的$k$</p>
</blockquote>
<script type="math/tex; mode=display">
\begin{array}{l}
\boldsymbol{f}_{j k}^{i}=\boldsymbol{s}_{j} \boldsymbol{W}_{i}^{r} \boldsymbol{r}_{i}+b_{i}^{r} \\
\hat{\boldsymbol{y}}_{j k}^{i}=\delta\left(\boldsymbol{f}_{j k}^{i} \boldsymbol{W}_{o}^{r}+b_{o}^{r}\right) 公式（3）
\end{array}</script><p>此时的Loss定义为：（$N_t$表示了什么？）</p>
<script type="math/tex; mode=display">
\begin{aligned}
L_{E v i} &=-\frac{1}{N_{t}} \frac{1}{N_{s}} \sum_{k=1}^{N_{t}} \sum_{j=1}^{N_{s}}\left(y_{j k}^{i} \log \left(\hat{\boldsymbol{y}}_{j k}^{i}\right)\right.\left.+\left(1-y_{j k}^{i}\right) \log \left(1-\hat{\boldsymbol{y}}_{j k}^{i}\right)\right)
\end{aligned}</script><h4 id="支撑句下的BERT微调："><a href="#支撑句下的BERT微调：" class="headerlink" title="支撑句下的BERT微调："></a>支撑句下的BERT微调：</h4><p>依据BERT内部的 attention probabilities 来给予支撑句更高的attention value.</p>
<p>针对每一实体对($head$, $tail$),取BERT最后输出的$l$层中，由此计算出文档中的sentence们在当前实体对下的“所需要关注度” —$a_{sk}$（一顿操作并没有看懂，特别是维度那块看起来很奇怪…）</p>
<blockquote>
<p>下面的公式可以看作是对公式（3）的“微操”，为预测的支撑句加上权重。</p>
</blockquote>
<script type="math/tex; mode=display">
\hat{\boldsymbol{y}}_{k}^{i a}=\delta\left(\boldsymbol{a}_{s k} \boldsymbol{W}_{i}^{a} \boldsymbol{f}_{k}^{i}+b_{i}^{a}\right)</script><p>此时Loss如下：</p>
<script type="math/tex; mode=display">
\begin{aligned}
L_{E v i}^{a} &=-\frac{1}{N_{t}} \frac{1}{N_{s}} \sum_{k=1}^{N_{t}} \sum_{j=1}^{N_{s}}\left(y_{j k}^{i a} \log \left(\hat{\boldsymbol{y}}_{j k}^{i a}\right)\right.\left.+\left(1-y_{j k}^{i a}\right) \log \left(1-\hat{\boldsymbol{y}}_{j k}^{i a}\right)\right)
\end{aligned}</script><h4 id="关系抽取与支撑句预测联合训练"><a href="#关系抽取与支撑句预测联合训练" class="headerlink" title="关系抽取与支撑句预测联合训练"></a>关系抽取与支撑句预测联合训练</h4><script type="math/tex; mode=display">
\operatorname{Loss}=L_{R E}+\lambda_{1} * L_{E v i}^{a}</script><blockquote>
<p>以上全部为自己的个人理解，文章出发点不错，但是很多地方都描述不清楚…!!</p>
</blockquote>
<h2 id="Experiment"><a href="#Experiment" class="headerlink" title="Experiment"></a>Experiment</h2><p>用了体量更大的模型RoBERTa-large在线test中取得不错的效果，换作BERT之后只在validation set上比较，这不是耍流氓吗？</p>
<div align="center">
        <img src="https://cdn.jsdelivr.net/gh/chenhaishun/test_pic@master/typora202103/12/230446-597435.png">  
    </a>
</div>

<ul>
<li><p>直到看到消融那里发现作者说联合训练效果是最差的？所以这篇文章到底说明了什么？还是我理解错了？</p>
<div align="center">
        <img src="https://cdn.jsdelivr.net/gh/chenhaishun/test_pic@master/typora202103/12/233822-176160.png">  
    </a>
</div>
</li>
<li><p>使用BERT最后三层效果最好，见TODO第二条；</p>
</li>
<li><p>attention可视化比较有意思，看了TODO第二条再反过来看吧。</p>
<p>结论：除了关注头尾实体之外，也开始关注于前后实体相关的短语，支撑句等区域。另外，attention value的scale也比baseline更大，更宽泛。。。</p>
</li>
</ul>
<h2 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h2><ul>
<li><p>新思路：先验（BERT）+推理（Graph）</p>
<p>相比较于精心构图，设计节点连接方式，BERT-based的方法确实稍微优雅些，应该在可解释性方面多投入一些精力，发挥出bert的全部潜力</p>
<ul>
<li>BERT内部attention ：What Does BERT Look At? An Analysis of BERT’s Attention</li>
</ul>
</li>
</ul>

        </div>

        
            <section class="post-copyright">
                
                    <p class="copyright-item">
                        <span>Author:</span>
                        <span>Chenhs</span>
                    </p>
                
                
                    <p class="copyright-item">
                        <span>Permalink:</span>
                        <span><a href="http://example.com/2021/03/19/Arxiv2020%20Entity%20and%20Evidence%20Guided%20Relation%20Extraction%20for%20DocRED/">http://example.com/2021/03/19/Arxiv2020%20Entity%20and%20Evidence%20Guided%20Relation%20Extraction%20for%20DocRED/</a></span>
                    </p>
                
                
                    <p class="copyright-item">
                        <span>License:</span>
                        <span>Copyright (c) 2019 <a target="_blank" rel="noopener" href="http://creativecommons.org/licenses/by-nc/4.0/">CC-BY-NC-4.0</a> LICENSE</span>
                    </p>
                
                
                     <p class="copyright-item">
                         <span>Slogan:</span>
                         <span>😀😁😂🤣😃😄😅😆</span>
                     </p>
                

            </section>
        
        <section class="post-tags">
            <div>
                <span>Tag(s):</span>
                <span class="tag">
                    
                    
                        <a href="/tags/Document-Level-RE/"># Document-Level RE</a>
                    
                        
                </span>
            </div>
            <div>
                <a href="javascript:window.history.back();">back</a>
                <span>· </span>
                <a href="/">home</a>
            </div>
        </section>
        <section class="post-nav">
            
                <a class="prev" rel="prev" href="/2021/03/24/AAAI2021%20Multi-view%20Inference%20for%20Relation%20Extraction%20with%20Uncertain%20Knowledge/">AAAI2021 | Multi-view Inference for Relation Extraction with Uncertain Knowledge</a>
            
            
            <a class="next" rel="next" href="/2021/03/13/EMNLP2020%20Double%20Graph%20Based%20Reasoning%20for%20Document-level%20Relation%20Extraction/">EMNLP2020 | Double Graph Based Reasoning for Document-level Relation Extraction</a>
            
        </section>


    </article>
</div>







        </div>
        <footer id="footer" class="footer">
    <div class="copyright">
        <span>© Chenhs | Powered by <a href="https://hexo.io" target="_blank">Hexo</a> & <a href="https://github.com/Siricee/hexo-theme-Chic" target="_blank">Chic</a>
  <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

<span class="site-uv">
    总访客量:
    <i class="busuanzi-value" id="busuanzi_value_site_uv"></i>
</span>&nbsp;


<span class="site-pv">
    总访问量:
    <i class="busuanzi-value" id="busuanzi_value_site_pv"></i>
</span>

</span>
    </div>
</footer>

    </div>
</body>
</html>
